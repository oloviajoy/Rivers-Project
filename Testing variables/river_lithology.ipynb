{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a678e250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib\n",
    "import json\n",
    "\n",
    "#import locations of river data\n",
    "stations=pd.read_csv('river_loc_data_2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "074b4bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 792 points queried"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sources' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/v9/0fg88q9x1ts1bm2hlqzzjvwr0000gn/T/ipykernel_35877/2332988477.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m#dataframe of returned: map sources, map scale and map \"rank\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     tmp_ranks=pd.DataFrame(list(zip([t['source_id'] for t in tmp],\n\u001b[0;32m---> 26\u001b[0;31m                                 \u001b[0;34m[\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                       [source_ranks[sources[t['source_id']]] for t in tmp])),\n\u001b[1;32m     28\u001b[0m             columns=['source_id','scale','rank'])\n",
      "\u001b[0;32m/var/folders/v9/0fg88q9x1ts1bm2hlqzzjvwr0000gn/T/ipykernel_35877/2332988477.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m#dataframe of returned: map sources, map scale and map \"rank\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     tmp_ranks=pd.DataFrame(list(zip([t['source_id'] for t in tmp],\n\u001b[0;32m---> 26\u001b[0;31m                                 \u001b[0;34m[\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                       [source_ranks[sources[t['source_id']]] for t in tmp])),\n\u001b[1;32m     28\u001b[0m             columns=['source_id','scale','rank'])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sources' is not defined"
     ]
    }
   ],
   "source": [
    "#lists to be filled in loop below\n",
    "stn_lith=[]\n",
    "stn_t_age=[]\n",
    "stn_b_age=[]\n",
    "map_rank=[]\n",
    "stn_macro_units=[]\n",
    "stn_strat_names=[]\n",
    "\n",
    "#loop through station locations\n",
    "for i,s in stations.iterrows():\n",
    "    print('\\r%s out of %s points queried' % (i+1,len(stations)),end='')\n",
    "    \n",
    "    #macrostrat API for geologic map information at station lat / long\n",
    "    url='https://macrostrat.org/api/v2/geologic_units/map?lat=%s&lng=%s' % (s['lat'],s['long'])\n",
    "#     url='https://macrostrat.org/api/v2/geologic_units/map?lat=40.588848&lng=-109.465414'\n",
    "\n",
    "    #load the data as a list of dictionaries\n",
    "    tmp=urllib.request.urlopen(url)\n",
    "    tmp=json.load(tmp)['success']['data']\n",
    "    \n",
    "    #ditch any map polygons that do not have lithologies\n",
    "    tmp=[t for t in tmp if len(t['liths'])!=0]\n",
    "    \n",
    "    #dataframe of returned: map sources, map scale and map \"rank\"\n",
    "    tmp_ranks=pd.DataFrame(list(zip([t['source_id'] for t in tmp],\n",
    "                                [sources[t['source_id']] for t in tmp],\n",
    "                      [source_ranks[sources[t['source_id']]] for t in tmp])),\n",
    "            columns=['source_id','scale','rank'])\n",
    "\n",
    "    #record the lowest (largest) map rank found\n",
    "    map_rank.append(np.min(tmp_ranks['rank']))\n",
    "    \n",
    "    #find sources that match this largest scale\n",
    "    min_ranks=tmp_ranks['source_id'][tmp_ranks['rank']==np.min(tmp_ranks['rank'])].tolist()\n",
    "    \n",
    "    #only save map polygons that match this largest scale\n",
    "    tmp=[t for t in tmp if t['source_id'] in min_ranks]\n",
    "    \n",
    "    #gather lithology, age, and unit information for this lat/long\n",
    "    liths=[]\n",
    "    t_age=[]\n",
    "    b_age=[]\n",
    "    macro_units=[]\n",
    "    strat_names=[]\n",
    "    \n",
    "    #loop through all map polygons\n",
    "    for t in tmp:\n",
    "        #lithology IDs\n",
    "        liths.extend(t['liths'])\n",
    "        \n",
    "        #macrostrat units\n",
    "        macro_units.extend(t['macro_units'])\n",
    "        \n",
    "        #strat name_ids\n",
    "        strat_names.extend(t['strat_names'])\n",
    "        \n",
    "        #age information, if it exists\n",
    "        if t['t_age']!=None:\n",
    "            t_age.append(t['t_int_age'])\n",
    "        if t['b_age']!=None:\n",
    "            b_age.append(t['b_int_age'])\n",
    "            \n",
    "    #record lithology and unit information as pipe-separated string\n",
    "    stn_lith.append('|'.join({str(l) for l in liths}))\n",
    "    stn_macro_units.append('|'.join({str(l) for l in macro_units}))\n",
    "    stn_strat_names.append('|'.join({str(l) for l in strat_names}))\n",
    "\n",
    "    #record top age as AVERAGE of all top ages found\n",
    "    if len(t_age)!=0:\n",
    "        stn_t_age.append(np.mean(np.array(t_age)))\n",
    "    else:\n",
    "        stn_t_age.append(-9999.0)\n",
    "        \n",
    "    #record bottom age as AVERAGE of all bottom ages found\n",
    "    if len(b_age)!=0:\n",
    "        stn_b_age.append(np.mean(np.array(b_age)))\n",
    "    else:\n",
    "        stn_b_age.append(-9999.0)\n",
    "        \n",
    "        \n",
    "#append all gathered data to original dataframe\n",
    "stations['lith']=stn_lith\n",
    "stations['stn_t_age']=stn_t_age\n",
    "stations['stn_b_age']=stn_b_age\n",
    "stations['stn_macro_units']=stn_macro_units\n",
    "stations['stn_strat_names']=stn_strat_names\n",
    "stations['map_rank']=map_rank\n",
    "        \n",
    "#save your work\n",
    "stations.to_csv('stations_macrostrat.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db8e026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in previously macrostrat-linked stations\n",
    "stations=pd.read_csv('stations_macrostrat.csv')\n",
    "\n",
    "#download macrostrat's carbonate lithology library\n",
    "carb_liths=urllib.request.urlopen('https://macrostrat.org/api/v2/defs/lithologies?lith_type=carbonate')\n",
    "carb_liths=json.load(carb_liths)['success']['data']\n",
    "\n",
    "#dolomite lithology IDs\n",
    "dol_liths={c['lith_id'] for c in carb_liths if c['name']=='dolomite' or c['name']=='dolostone'}\n",
    "#all carbonate lithology IDs\n",
    "carb_liths={c['lith_id'] for c in carb_liths}\n",
    "\n",
    "#download macrostrat's igneous lithology library\n",
    "igneous_liths=urllib.request.urlopen('https://macrostrat.org/api/v2/defs/lithologies?lith_class=igneous')\n",
    "igneous_liths=json.load(igneous_liths)['success']['data']\n",
    "igneous_liths={c['lith_id'] for c in igneous_liths}\n",
    "\n",
    "#download macrostrat's siliciclastic lithology library\n",
    "sil_liths=urllib.request.urlopen('https://macrostrat.org/api/v2/defs/lithologies?lith_type=siliciclastic')\n",
    "sil_liths=json.load(sil_liths)['success']['data']\n",
    "sil_liths={c['lith_id'] for c in sil_liths}\n",
    "\n",
    "#lists to be filled in loop below\n",
    "frac_dol=[]\n",
    "frac_carb=[]\n",
    "frac_igneous=[]\n",
    "frac_sil=[]\n",
    "\n",
    "#loop through each station\n",
    "for i,c in stations.iterrows():\n",
    "    #make lithologies in this station into a set of integers (if lithologies were found)\n",
    "    if c['lith']!='' and type(c['lith'])!=float:\n",
    "        tmp_liths=set([int(l) for l in c['lith'].split('|')])\n",
    "    else:\n",
    "        tmp_liths={-9999}\n",
    "    \n",
    "    #tabulate fraction dolomite lithologies found\n",
    "    tmp=tmp_liths.intersection(dol_liths)\n",
    "    frac_dol.append(len(tmp)/len(tmp_liths))\n",
    "    \n",
    "    #tabulate fraction carbonate lithologies found\n",
    "    tmp=tmp_liths.intersection(carb_liths)\n",
    "    frac_carb.append(len(tmp)/len(tmp_liths))\n",
    "    \n",
    "    #tabulate fraction igneous lithologies found\n",
    "    tmp=tmp_liths.intersection(igneous_liths)\n",
    "    frac_igneous.append(len(tmp)/len(tmp_liths))\n",
    "\n",
    "    #tabulate fraction siliciclastic lithologies found\n",
    "    tmp=tmp_liths.intersection(sil_liths)\n",
    "    frac_sil.append(len(tmp)/len(tmp_liths))\n",
    "    \n",
    "#record these fractions into original dataframe\n",
    "stations['frac_dol']=frac_dol\n",
    "stations['frac_carb']=frac_carb\n",
    "stations['frac_sil']=frac_sil\n",
    "stations['frac_igneous']=frac_igneous\n",
    "\n",
    "#save your work\n",
    "stations.to_csv('stations_macrostrat.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
